#!/usr/bin/env node

/**
 * Script para actualizar automÃ¡ticamente los datos de presas canarias
 * Ejecuta el scraping y actualiza el CSV cada hora
 */

import { exec } from 'child_process';
import { promisify } from 'util';
import path from 'path';
import { fileURLToPath } from 'url';

const execAsync = promisify(exec);
const __filename = fileURLToPath(import.meta.url);
const __dirname = path.dirname(__filename);

// ConfiguraciÃ³n
const SCRAPING_DIR = path.join(__dirname, 'integrations', 'scraping-presas-canarias');
const FRONTEND_PUBLIC_DIR = path.join(__dirname, 'front', 'public');
const CSV_SOURCE = path.join(SCRAPING_DIR, 'presas_canarias.csv');
const CSV_DEST = path.join(FRONTEND_PUBLIC_DIR, 'presas_canarias.csv');

/**
 * Ejecuta el scraping de datos
 */
async function executeScraping() {
  try {
    console.log('ğŸ”„ Iniciando actualizaciÃ³n de datos de presas...');
    console.log('ğŸ“… Fecha:', new Date().toLocaleString('es-ES'));
    
    // Ejecutar el scraper
    console.log('ğŸš€ Ejecutando scraping...');
    const { stdout, stderr } = await execAsync('npm run dev', { 
      cwd: SCRAPING_DIR,
      timeout: 60000 // 60 segundos timeout
    });
    
    if (stderr && !stderr.includes('WARN')) {
      console.error('âš ï¸  Advertencias durante el scraping:', stderr);
    }
    
    console.log('âœ… Scraping completado');
    
    // Copiar datos actualizados al frontend
    console.log('ğŸ“‹ Copiando datos actualizados al frontend...');
    await execAsync(`cp "${CSV_SOURCE}" "${CSV_DEST}"`);
    
    console.log('âœ… Datos actualizados correctamente');
    console.log('ğŸŒ Los datos estÃ¡n disponibles en: http://localhost:3000');
    console.log('â° PrÃ³xima actualizaciÃ³n en 1 hora\n');
    
  } catch (error) {
    console.error('âŒ Error durante la actualizaciÃ³n:', error.message);
    throw error;
  }
}

/**
 * Programa las actualizaciones cada hora
 */
function scheduleUpdates() {
  console.log('ğŸ• Configurando actualizaciones automÃ¡ticas cada hora...');
  console.log('â° Primera actualizaciÃ³n en proceso...\n');
  
  // Ejecutar inmediatamente la primera vez
  executeScraping()
    .then(() => {
      // Programar ejecuciones cada hora (3600000 ms)
      setInterval(async () => {
        try {
          await executeScraping();
        } catch (error) {
          console.error('âŒ Error en actualizaciÃ³n programada:', error.message);
          console.log('â° Continuando con el programa de actualizaciones...\n');
        }
      }, 3600000); // 1 hora = 3600000 ms
    })
    .catch((error) => {
      console.error('âŒ Error en la primera actualizaciÃ³n:', error.message);
      process.exit(1);
    });
}

/**
 * Maneja la terminaciÃ³n del proceso
 */
function handleExit() {
  process.on('SIGINT', () => {
    console.log('\nğŸ›‘ Deteniendo actualizaciones automÃ¡ticas...');
    console.log('ğŸ‘‹ Â¡Hasta pronto!');
    process.exit(0);
  });
  
  process.on('SIGTERM', () => {
    console.log('\nğŸ›‘ Proceso terminado');
    process.exit(0);
  });
}

// Verificar que los directorios existen
import fs from 'fs';

if (!fs.existsSync(SCRAPING_DIR)) {
  console.error('âŒ Directorio de scraping no encontrado:', SCRAPING_DIR);
  process.exit(1);
}

if (!fs.existsSync(FRONTEND_PUBLIC_DIR)) {
  console.error('âŒ Directorio pÃºblico del frontend no encontrado:', FRONTEND_PUBLIC_DIR);
  process.exit(1);
}

// Iniciar el programa
console.log('ğŸï¸  ACTUALIZADOR AUTOMÃTICO DE PRESAS CANARIAS');
console.log('===============================================');
console.log('ğŸ“Š Datos se actualizarÃ¡n cada hora desde:');
console.log('ğŸŒ https://www.aguasgrancanaria.com/presas/ubicacion_presas.php');
console.log('ğŸ’¾ CSV destino:', CSV_DEST);
console.log('');

handleExit();
scheduleUpdates();